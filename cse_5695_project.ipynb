{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Penguini128/CSE-5695-Project/blob/main/cse_5695_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSE 5695\n",
        "\n",
        "## Running this notebook\n",
        "\n",
        "Before you run this notebook on Colab, make sure you do the following: On the left side of the Colab page, click on the Secrets menu (key icon). Make sure you have created two secrets, named `GH_TOKEN` and `GH_USERNAME`, with values equal to a personal access token for your GitHub account, and your GitHub username, respectively. Then, you should be able to run the cells below.\n",
        "\n",
        "If a popup appears asking to grant access to these secrets, make sure to enable access for the notebook."
      ],
      "metadata": {
        "id": "Czo6amYuSdYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install all dependencies"
      ],
      "metadata": {
        "id": "_XOZQtU8Sk-1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSgD3rjJNTx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76bb5fe8-9683-453e-f4fe-afb690266e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CSE-5695-Project'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "Receiving objects: 100% (108/108), 77.85 KiB | 648.00 KiB/s, done.\n",
            "remote: Total 108 (delta 22), reused 65 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Resolving deltas: 100% (22/22), done.\n",
            "/content/CSE-5695-Project\n",
            "Already up to date.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GH_TOKEN = userdata.get('GH_TOKEN')\n",
        "GH_USERNAME = userdata.get('GH_USERNAME')\n",
        "\n",
        "! git clone https://{GH_USERNAME}:{GH_TOKEN}@github.com/Penguini128/CSE-5695-Project\n",
        "%cd CSE-5695-Project\n",
        "! git pull\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install medmnist\n",
        "%pip install torchinfo"
      ],
      "metadata": {
        "id": "z8oRjMvVQVMm",
        "outputId": "87d11fb5-377f-438a-ea0c-276e997c6c3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from medmnist) (11.3.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.24.0+cu126)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->medmnist) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->medmnist) (3.0.3)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.1 medmnist-3.0.2\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "\n",
        "!gdown --folder \"https://drive.google.com/drive/folders/128YocnfqwhL5qwZ_02D8UotbfBDMV5u-?usp=drive_link\""
      ],
      "metadata": {
        "id": "Td6qiZ9rf-fW",
        "outputId": "c5abb3fd-ac45-4574-a80e-2cb5d5a6d095",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.11.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Retrieving folder contents\n",
            "Retrieving folder 1MbLhT95EBHbEzUrRIX0ujCV3Z08c05-B models\n",
            "Processing file 1RspVAm3VVjQvyL6oUeZ58WxvM4cwhvXS resnet-preloaded-weights-added-last-layer-full-model-trained.pth\n",
            "Processing file 1vLR19SrpqHRU5NVZ2ghMvJeSrbXZyBb8 resnet-preloaded-weights-swapped-last-layer-full-model-trained.pth\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1RspVAm3VVjQvyL6oUeZ58WxvM4cwhvXS\n",
            "From (redirected): https://drive.google.com/uc?id=1RspVAm3VVjQvyL6oUeZ58WxvM4cwhvXS&confirm=t&uuid=a27d7415-6beb-4245-9d9c-55dd914ac958\n",
            "To: /content/cse_5695_project_drive/models/resnet-preloaded-weights-added-last-layer-full-model-trained.pth\n",
            "100% 45.1M/45.1M [00:00<00:00, 60.0MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1vLR19SrpqHRU5NVZ2ghMvJeSrbXZyBb8\n",
            "From (redirected): https://drive.google.com/uc?id=1vLR19SrpqHRU5NVZ2ghMvJeSrbXZyBb8&confirm=t&uuid=b479dcac-6b36-4cda-958a-66e20903464e\n",
            "To: /content/cse_5695_project_drive/models/resnet-preloaded-weights-swapped-last-layer-full-model-trained.pth\n",
            "100% 44.9M/44.9M [00:00<00:00, 56.9MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages\n",
        "(All import statements should go in the cell below)"
      ],
      "metadata": {
        "id": "ZqAJZKLdSqsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from medmnist import OCTMNIST\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from torchvision import transforms\n",
        "from torchinfo import summary\n",
        "from torch.utils.data import DataLoader\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "qGNJc73Aqgf3",
        "outputId": "a8040b74-2911-4606-805d-b4a818b2906d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMBAL_PATH = 'CSE-5695-Project'\n",
        "sys.path.append(IMBAL_PATH)\n",
        "import imbal"
      ],
      "metadata": {
        "id": "d_OlUdj5itGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7dc23e-c3d7-4cd1-94e4-bc7e976d8da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Functions"
      ],
      "metadata": {
        "id": "odeWLf-3SzVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "        model=None,\n",
        "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "        loss_fn=None,\n",
        "        optimizer=None,\n",
        "        epochs=10,\n",
        "        lr_scheduler=None,\n",
        "        training_data=None,\n",
        "        validation_data=None,\n",
        "):\n",
        "    for layer in model.children():\n",
        "       if hasattr(layer, 'reset_parameters'):\n",
        "           layer.reset_parameters()\n",
        "\n",
        "    training_loss_curve = []\n",
        "    training_accuracy_curve = []\n",
        "    validation_loss_curve = []\n",
        "    validation_accuracy_curve = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_samples = 0\n",
        "        total_loss_contributions = 0\n",
        "        correct = 0\n",
        "\n",
        "        if lr_scheduler is not None:\n",
        "            print(f\"Epoch {epoch+1} Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "        for index, data in enumerate(training_data):\n",
        "            sample_weights = None\n",
        "            if len(data) == 2:\n",
        "              images, labels = data\n",
        "            else:\n",
        "              images, labels, sample_weights = data\n",
        "              sample_weights = sample_weights.to(device)\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            if labels.ndim == 2 and labels.shape[1] > 1:\n",
        "              labels = torch.argmax(labels, dim=1)\n",
        "            labels = torch.reshape(labels, (-1,))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            per_sample_losses = loss_fn(outputs, labels)\n",
        "\n",
        "            if sample_weights is not None:\n",
        "                # Squeeze sample_weights to match per_sample_losses shape if it's (batch_size, 1)\n",
        "                if sample_weights.dim() > 1:\n",
        "                    sample_weights = sample_weights.squeeze()\n",
        "                weighted_per_sample_losses = per_sample_losses * sample_weights\n",
        "                batch_loss = weighted_per_sample_losses.mean() # Mean of weighted losses for this batch\n",
        "                running_loss += weighted_per_sample_losses.sum().item() # Sum of weighted losses for accumulation\n",
        "                total_loss_contributions += sample_weights.sum().item() # Sum of weights for normalization\n",
        "            else:\n",
        "                batch_loss = per_sample_losses.mean() # Mean of unweighted losses for this batch\n",
        "                running_loss += per_sample_losses.sum().item() # Sum of unweighted losses for accumulation\n",
        "                total_loss_contributions += labels.size(0) # Number of samples for normalization\n",
        "\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            batch_correct = (predicted == labels).sum().item()\n",
        "            correct += batch_correct\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}],\",\n",
        "                  f\"Batch [{index}/{len(training_data)}],\",\n",
        "                  f\"Loss: {batch_loss.item():.4f},\",\n",
        "                  f\"Accuracy: {batch_correct/labels.size(0)*100:.2f}%\",\n",
        "                  end='\\r')\n",
        "\n",
        "        epoch_loss = running_loss / total_loss_contributions if total_loss_contributions > 0 else 0\n",
        "\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        training_loss_curve.append(epoch_loss)\n",
        "        training_accuracy_curve.append(correct/total_samples)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}],\",\n",
        "              f\"Batch [{len(training_data)}/{len(training_data)}],\",\n",
        "              f\"Loss: {epoch_loss:.4f},\",\n",
        "              f\"Accuracy: {correct/total_samples*100:.2f}%\",\n",
        "              end='\\r' if validation_data is not None else '\\n')\n",
        "\n",
        "        if validation_data is not None:\n",
        "            model.eval()\n",
        "            val_correct = 0\n",
        "            val_loss_accum = 0 # Accumulate sum of unweighted losses\n",
        "            val_total_samples = 0\n",
        "            with torch.no_grad():\n",
        "                for index, data in enumerate(validation_data):\n",
        "                    images, labels = data\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    labels = torch.argmax(labels, dim=1)\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    val_total_samples += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "                    val_batch_loss_per_sample = loss_fn(outputs, labels) # Still reduction='none'\n",
        "                    val_batch_loss_mean = val_batch_loss_per_sample.mean() # Take mean for display/accumulation\n",
        "                    val_loss_accum += val_batch_loss_per_sample.sum().item() # Sum of unweighted losses\n",
        "\n",
        "                    print(f\"Epoch [{epoch+1}/{epochs}],\",\n",
        "                          f\"Batch [{len(training_data)}/{len(training_data)}],\",\n",
        "                          f\"Loss: {epoch_loss:.4f},\",\n",
        "                          f\"Accuracy: {correct/total_samples*100:.2f}%,\",\n",
        "                          f\"Validation Loss: {val_batch_loss_mean.item():.4f},\",\n",
        "                          f\"Validation Accuracy: {100 * val_correct / val_total_samples:.2f}%\",\n",
        "                          end='\\r')\n",
        "\n",
        "                val_epoch_loss = val_loss_accum / val_total_samples\n",
        "                validation_loss_curve.append(val_epoch_loss)\n",
        "                validation_accuracy_curve.append(val_correct / val_total_samples)\n",
        "\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}],\",\n",
        "                      f\"Batch [{len(training_data)}/{len(training_data)}],\",\n",
        "                      f\"Loss: {epoch_loss:.4f},\",\n",
        "                      f\"Accuracy: {correct/total_samples*100:.2f}%,\",\n",
        "                      f\"Validation Loss: {val_epoch_loss:.4f},\",\n",
        "                      f\"Validation Accuracy: {100 * val_correct / val_total_samples:.2f}%\",\n",
        "                      end='\\n')\n",
        "    print('Done!')\n",
        "    return training_loss_curve, training_accuracy_curve, validation_loss_curve, validation_accuracy_curve\n",
        "\n",
        "def eval(\n",
        "    model=None,\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    loss_fn=None, # Expects loss_fn with reduction='none'\n",
        "    test_data=None,\n",
        "):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    loss_accum = 0 # Accumulate sum of unweighted losses\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for index, data in enumerate(test_data):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = torch.argmax(labels, dim=1)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            per_sample_losses = loss_fn(outputs, labels) # reduction='none'\n",
        "            batch_loss_mean = per_sample_losses.mean() # Mean for display\n",
        "            loss_accum += per_sample_losses.sum().item() # Sum for epoch total\n",
        "            print(f\"Loss: {batch_loss_mean.item():.4f}, Accuracy [{index+1}/{len(test_data)}]: {100 * correct / total_samples:.2f}%\", end='\\r')\n",
        "    print(' '*50, end='\\r')\n",
        "    epoch_loss = loss_accum / total_samples\n",
        "    print(f\"Loss: {epoch_loss:.4f}, Accuracy: {100 * correct / total_samples:.2f}%\")"
      ],
      "metadata": {
        "id": "z4nmDjSesyvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load OCTMNIST data"
      ],
      "metadata": {
        "id": "3jSkzAR1S391"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = OCTMNIST(split='train', download=True, transform=data_transform)\n",
        "val_dataset = OCTMNIST(split='val', download=True, transform=data_transform)\n",
        "test_dataset = OCTMNIST(split='test', download=True, transform=data_transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "iIwSoPRmtoqB",
        "outputId": "269842c9-0c4d-420d-9fdc-b9fe1ab5e2ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 54.9M/54.9M [00:03<00:00, 14.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "benchmark_model = benchmark_model.to(device)\n",
        "print(benchmark_model)"
      ],
      "metadata": {
        "id": "cXYfd5hnq-pK",
        "outputId": "e60db035-2bc7-4373-f11b-0542e8b3c9c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 118MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_model.fc = torch.nn.Linear(in_features=512, out_features=4).to(device)"
      ],
      "metadata": {
        "id": "aLkUY884rYCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in benchmark_model.parameters():\n",
        "  param.requires_grad = True\n",
        "# for param in benchmark_model.fc.parameters():\n",
        "#   param.requires_grad = True\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "def lr_function(epoch):\n",
        "  if epoch >= 75:\n",
        "    return 0.01\n",
        "  elif epoch >= 50:\n",
        "    return 0.1\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "optimizer = optim.Adam(benchmark_model.parameters(), lr=0.001)\n",
        "lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_function)"
      ],
      "metadata": {
        "id": "8Bf_eF1Zr3jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "    model=benchmark_model,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    training_data=train_loader,\n",
        "    validation_data=val_loader\n",
        ")"
      ],
      "metadata": {
        "id": "fbfjsGyQixDe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "e7a5a93b-1cbd-4a10-be5a-ca8aac4cd7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Learning Rate: 0.001\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1904208138.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbenchmark_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1365335680.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, loss_fn, optimizer, epochs, lr_scheduler, training_data, validation_data)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(\n",
        "    model=benchmark_model,\n",
        "    loss_fn=loss_fn,\n",
        "    test_data=test_loader\n",
        ")"
      ],
      "metadata": {
        "id": "8yBHVRyWttK1",
        "outputId": "05a5ecb3-1a3a-4500-ae28-e559d06fb6b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0000, Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_model.eval()\n"
      ],
      "metadata": {
        "id": "D4KHCenjxr4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "JldfR6bKd8gM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_SAVE_PATH = 'temp.pth'\n",
        "INPUT_SHAPE = (28, 28, 3)\n",
        "with torch.no_grad():\n",
        "    trace = torch.jit.trace(benchmark_model, torch.randn(INPUT_SHAPE))\n",
        "torch.jit.save(trace, MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "wViZIqkceC1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ],
      "metadata": {
        "id": "eZmZsLWSd7Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_LOAD_PATH = 'cse_5695_project_drive/models/resnet-4-class-last-layer.pth'\n",
        "loaded_model = torch.jit.load(MODEL_LOAD_PATH)"
      ],
      "metadata": {
        "id": "O5alxeG_eDEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(\n",
        "    model=loaded_model,\n",
        "    loss_fn=loss_fn,\n",
        "    test_data=val_loader\n",
        ")"
      ],
      "metadata": {
        "id": "wh66wwibiD49",
        "outputId": "dcf5afd3-a9c2-4abd-d16a-29f8a2dd05a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.1475, Accuracy: 29.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_load = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
        "images, labels = next(iter(train_load))\n",
        "images = images.numpy()\n",
        "labels = labels.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1zZ_ArCAGHl",
        "outputId": "2b22d80e-1287-4c07-8428-1a25e5ee3d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(97477, 3, 28, 28)\n",
            "(97477, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = imbal.classification.generate_weights(\n",
        "    labels\n",
        ")\n",
        "\n",
        "unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
        "print(unique_labels[[3, 0, 1, 2]])\n",
        "print(label_counts[[3, 0, 1, 2]])\n",
        "weights *= len(weights)\n",
        "\n",
        "uniques = np.unique(weights)\n",
        "print(uniques)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB44wnDPCjZ-",
        "outputId": "c0ad66d4-e05e-459c-a601-fcf4de2df35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 0 1 2]\n",
            "[46026 33484 10213  7754]\n",
            "[0.52946704 0.7277879  2.38610105 3.14279727]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from math import ceil\n",
        "from imbal.util.constants import ModelType\n",
        "\n",
        "class DatasetWithBatchingTorch(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        x_set,\n",
        "        y_set,\n",
        "        sample_weights=None,\n",
        "        batch_size=64,\n",
        "        num_batches=None,\n",
        "        seed=0,\n",
        "        shuffle=True,\n",
        "        mode=ModelType.CLASSIFICATION,\n",
        "        sort=\"descending\"\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.seed = seed\n",
        "        self.shuffle = shuffle\n",
        "        self.mode = mode\n",
        "        self.sort = sort\n",
        "\n",
        "        x = torch.tensor(x_set)\n",
        "        y = torch.tensor(y_set).view(-1)\n",
        "\n",
        "        if sample_weights is None:\n",
        "            sw = torch.ones(len(x)) / len(x)\n",
        "        else:\n",
        "            sw = torch.tensor(sample_weights).view(-1)\n",
        "\n",
        "        if num_batches is None:\n",
        "            num_batches = ceil(len(x) / batch_size)\n",
        "\n",
        "        self.num_batches = num_batches\n",
        "\n",
        "        # Regression: sort data then divide into pseudo-classes\n",
        "        if mode == ModelType.REGRESSION:\n",
        "            if sort == \"descending\":\n",
        "                order = torch.argsort(y, descending=True)\n",
        "            else:\n",
        "                order = torch.argsort(y)\n",
        "\n",
        "            x = x[order]\n",
        "            y = y[order]\n",
        "            sw = sw[order]\n",
        "\n",
        "            class_counts = [num_batches] * (len(y) // num_batches)\n",
        "            class_counts.append(len(y) % num_batches)\n",
        "            class_labels = [1] * len(class_counts)\n",
        "\n",
        "        else:\n",
        "            # Classification: find true classes\n",
        "            class_labels, inverse, class_counts = torch.unique(y, return_inverse=True, return_counts=True)\n",
        "            class_labels = class_labels.tolist()\n",
        "            class_counts = class_counts.tolist()\n",
        "\n",
        "        # Build stratified/duplicated lists\n",
        "        data_by_class = []\n",
        "        labels_by_class = []\n",
        "        weights_by_class = []\n",
        "\n",
        "        g = torch.Generator().manual_seed(seed)\n",
        "\n",
        "        for i, (label, count) in enumerate(zip(class_labels, class_counts)):\n",
        "            if mode == ModelType.CLASSIFICATION:\n",
        "                mask = (y == label)\n",
        "                class_x = x[mask]\n",
        "                class_y = y[mask]\n",
        "                class_w = sw[mask]\n",
        "\n",
        "                duplicate_factor = ceil(num_batches / count)\n",
        "\n",
        "            else:\n",
        "                start = i * num_batches\n",
        "                end = start + count\n",
        "                class_x = x[start:end]\n",
        "                class_y = y[start:end]\n",
        "                class_w = sw[start:end]\n",
        "\n",
        "                duplicate_factor = 1\n",
        "\n",
        "            class_w = class_w / duplicate_factor\n",
        "\n",
        "            # Shuffle\n",
        "            if shuffle:\n",
        "                idx = torch.randperm(len(class_x), generator=g)\n",
        "                class_x = class_x[idx]\n",
        "                class_y = class_y[idx]\n",
        "                class_w = class_w[idx]\n",
        "\n",
        "            # Duplicate\n",
        "            class_x = class_x.repeat((duplicate_factor,) + (1,) * (class_x.ndim - 1))\n",
        "            class_y = class_y.repeat(duplicate_factor)\n",
        "            class_w = class_w.repeat(duplicate_factor)\n",
        "\n",
        "            data_by_class.append(class_x)\n",
        "            labels_by_class.append(class_y)\n",
        "            weights_by_class.append(class_w)\n",
        "\n",
        "        # Combine all classes\n",
        "        X = torch.cat(data_by_class, dim=0)\n",
        "        Y = torch.cat(labels_by_class, dim=0)\n",
        "        W = torch.cat(weights_by_class, dim=0)\n",
        "\n",
        "        # Build final batches by strided slicing\n",
        "        self.batches = []\n",
        "        for i in range(num_batches):\n",
        "            batch_x = X[i::num_batches]\n",
        "            batch_y = Y[i::num_batches].view(-1, 1)\n",
        "            batch_w = W[i::num_batches].view(-1, 1)\n",
        "\n",
        "            # Shuffle inside batch\n",
        "            if shuffle:\n",
        "                g2 = torch.Generator().manual_seed(seed + i)\n",
        "                idx = torch.randperm(len(batch_x), generator=g2)\n",
        "                batch_x = batch_x[idx]\n",
        "                batch_y = batch_y[idx]\n",
        "                batch_w = batch_w[idx]\n",
        "\n",
        "            self.batches.append((batch_x, batch_y, batch_w))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batches\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.batches[idx]"
      ],
      "metadata": {
        "id": "4T4glivMDWTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = DatasetWithBatchingTorch(\n",
        "    images,\n",
        "    labels,\n",
        "    sample_weights=weights,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "print(test_dataset[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHnXLR-PEMUo",
        "outputId": "fdd9b85c-8ec7-467a-8885-d13a28df6103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[[1.0000, 1.0000, 0.9922,  ..., 0.5686, 0.5451, 0.5373],\n",
            "          [0.4980, 0.4824, 0.4627,  ..., 0.1412, 0.1294, 0.1333],\n",
            "          [0.1608, 0.1569, 0.1490,  ..., 0.1333, 0.1333, 0.1412],\n",
            "          ...,\n",
            "          [0.0745, 0.0745, 0.0745,  ..., 0.0706, 0.0706, 0.0706],\n",
            "          [0.0667, 0.0667, 0.0667,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0627, 0.0627,  ..., 0.0588, 0.0588, 0.0588]],\n",
            "\n",
            "         [[1.0000, 1.0000, 0.9922,  ..., 0.5686, 0.5451, 0.5373],\n",
            "          [0.4980, 0.4824, 0.4627,  ..., 0.1412, 0.1294, 0.1333],\n",
            "          [0.1608, 0.1569, 0.1490,  ..., 0.1333, 0.1333, 0.1412],\n",
            "          ...,\n",
            "          [0.0745, 0.0745, 0.0745,  ..., 0.0706, 0.0706, 0.0706],\n",
            "          [0.0667, 0.0667, 0.0667,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0627, 0.0627,  ..., 0.0588, 0.0588, 0.0588]],\n",
            "\n",
            "         [[1.0000, 1.0000, 0.9922,  ..., 0.5686, 0.5451, 0.5373],\n",
            "          [0.4980, 0.4824, 0.4627,  ..., 0.1412, 0.1294, 0.1333],\n",
            "          [0.1608, 0.1569, 0.1490,  ..., 0.1333, 0.1333, 0.1412],\n",
            "          ...,\n",
            "          [0.0745, 0.0745, 0.0745,  ..., 0.0706, 0.0706, 0.0706],\n",
            "          [0.0667, 0.0667, 0.0667,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0627, 0.0627,  ..., 0.0588, 0.0588, 0.0588]]],\n",
            "\n",
            "\n",
            "        [[[0.0588, 0.0588, 0.0588,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0627, 0.0627,  ..., 0.0667, 0.0667, 0.0667],\n",
            "          [0.0667, 0.0667, 0.0667,  ..., 0.0706, 0.0706, 0.0706],\n",
            "          ...,\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314],\n",
            "          [0.0275, 0.0275, 0.0275,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235]],\n",
            "\n",
            "         [[0.0588, 0.0588, 0.0588,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0627, 0.0627,  ..., 0.0667, 0.0667, 0.0667],\n",
            "          [0.0667, 0.0667, 0.0667,  ..., 0.0706, 0.0706, 0.0706],\n",
            "          ...,\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314],\n",
            "          [0.0275, 0.0275, 0.0275,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235]],\n",
            "\n",
            "         [[0.0588, 0.0588, 0.0588,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0627, 0.0627,  ..., 0.0667, 0.0667, 0.0667],\n",
            "          [0.0667, 0.0667, 0.0667,  ..., 0.0706, 0.0706, 0.0706],\n",
            "          ...,\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314],\n",
            "          [0.0275, 0.0275, 0.0275,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235]]],\n",
            "\n",
            "\n",
            "        [[[0.0706, 0.0706, 0.0784,  ..., 0.0706, 0.0667, 0.0627],\n",
            "          [0.0745, 0.0745, 0.0863,  ..., 0.0745, 0.0745, 0.0745],\n",
            "          [0.0706, 0.0667, 0.0784,  ..., 0.0627, 0.0667, 0.0745],\n",
            "          ...,\n",
            "          [0.0353, 0.0353, 0.0353,  ..., 0.0314, 0.0314, 0.0314],\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0275, 0.0275, 0.0275,  ..., 0.0235, 0.0235, 0.0235]],\n",
            "\n",
            "         [[0.0706, 0.0706, 0.0784,  ..., 0.0706, 0.0667, 0.0627],\n",
            "          [0.0745, 0.0745, 0.0863,  ..., 0.0745, 0.0745, 0.0745],\n",
            "          [0.0706, 0.0667, 0.0784,  ..., 0.0627, 0.0667, 0.0745],\n",
            "          ...,\n",
            "          [0.0353, 0.0353, 0.0353,  ..., 0.0314, 0.0314, 0.0314],\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0275, 0.0275, 0.0275,  ..., 0.0235, 0.0235, 0.0235]],\n",
            "\n",
            "         [[0.0706, 0.0706, 0.0784,  ..., 0.0706, 0.0667, 0.0627],\n",
            "          [0.0745, 0.0745, 0.0863,  ..., 0.0745, 0.0745, 0.0745],\n",
            "          [0.0706, 0.0667, 0.0784,  ..., 0.0627, 0.0667, 0.0745],\n",
            "          ...,\n",
            "          [0.0353, 0.0353, 0.0353,  ..., 0.0314, 0.0314, 0.0314],\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0275, 0.0275, 0.0275,  ..., 0.0235, 0.0235, 0.0235]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.0902, 0.0902, 0.0902,  ..., 0.0902, 0.0902, 0.0863],\n",
            "          [0.0941, 0.0941, 0.0941,  ..., 0.0980, 0.0980, 0.0941],\n",
            "          [0.0980, 0.0980, 0.0980,  ..., 0.0980, 0.0980, 0.0941],\n",
            "          ...,\n",
            "          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0471, 0.0471],\n",
            "          [0.0471, 0.0471, 0.0471,  ..., 0.0431, 0.0431, 0.0431],\n",
            "          [0.0392, 0.0392, 0.0392,  ..., 0.0353, 0.0353, 0.0353]],\n",
            "\n",
            "         [[0.0902, 0.0902, 0.0902,  ..., 0.0902, 0.0902, 0.0863],\n",
            "          [0.0941, 0.0941, 0.0941,  ..., 0.0980, 0.0980, 0.0941],\n",
            "          [0.0980, 0.0980, 0.0980,  ..., 0.0980, 0.0980, 0.0941],\n",
            "          ...,\n",
            "          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0471, 0.0471],\n",
            "          [0.0471, 0.0471, 0.0471,  ..., 0.0431, 0.0431, 0.0431],\n",
            "          [0.0392, 0.0392, 0.0392,  ..., 0.0353, 0.0353, 0.0353]],\n",
            "\n",
            "         [[0.0902, 0.0902, 0.0902,  ..., 0.0902, 0.0902, 0.0863],\n",
            "          [0.0941, 0.0941, 0.0941,  ..., 0.0980, 0.0980, 0.0941],\n",
            "          [0.0980, 0.0980, 0.0980,  ..., 0.0980, 0.0980, 0.0941],\n",
            "          ...,\n",
            "          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0471, 0.0471],\n",
            "          [0.0471, 0.0471, 0.0471,  ..., 0.0431, 0.0431, 0.0431],\n",
            "          [0.0392, 0.0392, 0.0392,  ..., 0.0353, 0.0353, 0.0353]]],\n",
            "\n",
            "\n",
            "        [[[0.1294, 0.1255, 0.1216,  ..., 0.1216, 0.1216, 0.1216],\n",
            "          [0.1451, 0.1412, 0.1333,  ..., 0.1216, 0.1216, 0.1216],\n",
            "          [0.1569, 0.1529, 0.1412,  ..., 0.1294, 0.1294, 0.1294],\n",
            "          ...,\n",
            "          [0.0667, 0.0667, 0.0667,  ..., 0.0588, 0.0627, 0.0627],\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.0549, 0.0549, 0.0588],\n",
            "          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0510, 0.0510]],\n",
            "\n",
            "         [[0.1294, 0.1255, 0.1216,  ..., 0.1216, 0.1216, 0.1216],\n",
            "          [0.1451, 0.1412, 0.1333,  ..., 0.1216, 0.1216, 0.1216],\n",
            "          [0.1569, 0.1529, 0.1412,  ..., 0.1294, 0.1294, 0.1294],\n",
            "          ...,\n",
            "          [0.0667, 0.0667, 0.0667,  ..., 0.0588, 0.0627, 0.0627],\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.0549, 0.0549, 0.0588],\n",
            "          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0510, 0.0510]],\n",
            "\n",
            "         [[0.1294, 0.1255, 0.1216,  ..., 0.1216, 0.1216, 0.1216],\n",
            "          [0.1451, 0.1412, 0.1333,  ..., 0.1216, 0.1216, 0.1216],\n",
            "          [0.1569, 0.1529, 0.1412,  ..., 0.1294, 0.1294, 0.1294],\n",
            "          ...,\n",
            "          [0.0667, 0.0667, 0.0667,  ..., 0.0588, 0.0627, 0.0627],\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.0549, 0.0549, 0.0588],\n",
            "          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0510, 0.0510]]],\n",
            "\n",
            "\n",
            "        [[[0.1725, 0.1569, 0.1451,  ..., 0.9686, 0.9882, 1.0000],\n",
            "          [0.1569, 0.1412, 0.1294,  ..., 0.4000, 0.4667, 0.5216],\n",
            "          [0.1451, 0.1333, 0.1176,  ..., 0.1294, 0.1373, 0.1333],\n",
            "          ...,\n",
            "          [0.0549, 0.0549, 0.0549,  ..., 0.0510, 0.0627, 0.2784],\n",
            "          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0667, 0.2863],\n",
            "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0745, 0.3020]],\n",
            "\n",
            "         [[0.1725, 0.1569, 0.1451,  ..., 0.9686, 0.9882, 1.0000],\n",
            "          [0.1569, 0.1412, 0.1294,  ..., 0.4000, 0.4667, 0.5216],\n",
            "          [0.1451, 0.1333, 0.1176,  ..., 0.1294, 0.1373, 0.1333],\n",
            "          ...,\n",
            "          [0.0549, 0.0549, 0.0549,  ..., 0.0510, 0.0627, 0.2784],\n",
            "          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0667, 0.2863],\n",
            "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0745, 0.3020]],\n",
            "\n",
            "         [[0.1725, 0.1569, 0.1451,  ..., 0.9686, 0.9882, 1.0000],\n",
            "          [0.1569, 0.1412, 0.1294,  ..., 0.4000, 0.4667, 0.5216],\n",
            "          [0.1451, 0.1333, 0.1176,  ..., 0.1294, 0.1373, 0.1333],\n",
            "          ...,\n",
            "          [0.0549, 0.0549, 0.0549,  ..., 0.0510, 0.0627, 0.2784],\n",
            "          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0667, 0.2863],\n",
            "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0745, 0.3020]]]]), tensor([[0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [1],\n",
            "        [1],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [0],\n",
            "        [3],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3],\n",
            "        [0],\n",
            "        [1],\n",
            "        [2],\n",
            "        [2],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3],\n",
            "        [0],\n",
            "        [1],\n",
            "        [3],\n",
            "        [1],\n",
            "        [3],\n",
            "        [0],\n",
            "        [3],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3],\n",
            "        [2],\n",
            "        [3],\n",
            "        [0],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [1],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [1],\n",
            "        [3],\n",
            "        [0],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [2],\n",
            "        [2],\n",
            "        [0],\n",
            "        [3],\n",
            "        [3],\n",
            "        [0],\n",
            "        [3],\n",
            "        [1],\n",
            "        [0],\n",
            "        [3],\n",
            "        [2],\n",
            "        [2],\n",
            "        [3],\n",
            "        [3],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [1],\n",
            "        [3],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [3],\n",
            "        [2],\n",
            "        [3],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [0],\n",
            "        [3],\n",
            "        [3],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3],\n",
            "        [3],\n",
            "        [0],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [2],\n",
            "        [3],\n",
            "        [3],\n",
            "        [1],\n",
            "        [3],\n",
            "        [0],\n",
            "        [3],\n",
            "        [2],\n",
            "        [1]]), tensor([[0.7278],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [2.3861],\n",
            "        [2.3861],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [2.3861],\n",
            "        [3.1428],\n",
            "        [3.1428],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [2.3861],\n",
            "        [0.5295],\n",
            "        [2.3861],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [2.3861],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [3.1428],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [2.3861],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [2.3861],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [3.1428],\n",
            "        [3.1428],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [2.3861],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [3.1428],\n",
            "        [3.1428],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [2.3861],\n",
            "        [0.5295],\n",
            "        [2.3861],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [2.3861],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [3.1428],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [3.1428],\n",
            "        [0.5295],\n",
            "        [0.5295],\n",
            "        [2.3861],\n",
            "        [0.5295],\n",
            "        [0.7278],\n",
            "        [0.5295],\n",
            "        [3.1428],\n",
            "        [2.3861]], dtype=torch.float64))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "    model=benchmark_model,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    training_data=test_dataset,\n",
        "    validation_data=val_loader\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5T9jNAqEWvt",
        "outputId": "2550e4cb-d09b-442e-e3f8-c73656a27eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Learning Rate: 0.001\n",
            "Epoch [1/100], Batch [762/762], Loss: 0.9825, Accuracy: 62.87%, Validation Loss: 2.7994, Validation Accuracy: 29.89%\n",
            "Epoch 2 Learning Rate: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temperature Scaling"
      ],
      "metadata": {
        "id": "MUInIvxgZvM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used benchmark model\n",
        "benchmark_model = resnet18(weights=None)\n",
        "benchmark_model.fc = torch.nn.Linear(in_features=512, out_features=4)\n",
        "benchmark_model = benchmark_model.to(device)\n",
        "print(benchmark_model)\n",
        "\n",
        "MODEL_SAVE_PATH = 'cse_5695_project_drive/models/resnet18_none.pth'\n",
        "model = benchmark_model\n",
        "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "ow_Itdz8aDqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelWithTemperature(nn.Module):\n",
        "    \"\"\"\n",
        "    A wrapper for models with temperature scaling calibration.\n",
        "    Temperature scaling is a single-parameter variant of Platt Scaling.\n",
        "    \"\"\"\n",
        "    def __init__(self, model):\n",
        "        super(ModelWithTemperature, self).__init__()\n",
        "        self.model = model\n",
        "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
        "\n",
        "    def forward(self, input):\n",
        "        logits = self.model(input)\n",
        "        return self.temperature_scale(logits)\n",
        "\n",
        "    def temperature_scale(self, logits):\n",
        "        \"\"\"\n",
        "        Perform temperature scaling on logits\n",
        "        \"\"\"\n",
        "        temperature = self.temperature.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
        "        return logits / temperature\n",
        "\n",
        "    def set_temperature(self, valid_loader):\n",
        "        \"\"\"\n",
        "        Tune the temperature parameter on the validation set.\n",
        "        Optimizes NLL (Negative Log Likelihood).\n",
        "        \"\"\"\n",
        "        self.to(device)\n",
        "        nll_criterion = nn.CrossEntropyLoss().to(device)\n",
        "        ece_criterion = ECELoss().to(device)\n",
        "\n",
        "        # Collect all logits and labels\n",
        "        logits_list = []\n",
        "        labels_list = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for input, label in tqdm.tqdm(valid_loader, desc=\"Collecting validation data\"):\n",
        "                input = input.to(device)\n",
        "                logits = self.model(input)\n",
        "                logits_list.append(logits)\n",
        "                labels_list.append(label)\n",
        "\n",
        "            logits = torch.cat(logits_list).to(device)\n",
        "            labels = torch.cat(labels_list).to(device)\n",
        "            if labels.dim() > 1:\n",
        "                labels = labels.squeeze()\n",
        "                if labels.dim() > 1:\n",
        "                    labels = labels[:, 0]\n",
        "            labels = labels.long()\n",
        "\n",
        "        # Calculate metrics before temperature scaling\n",
        "        before_temperature_nll = nll_criterion(logits, labels).item()\n",
        "        before_temperature_ece = ece_criterion(logits, labels).item()\n",
        "        print(f'Before temperature - NLL: {before_temperature_nll:.4f}, ECE: {before_temperature_ece:.4f}')\n",
        "\n",
        "        # Optimize temperature\n",
        "        optimizer = optim.LBFGS([self.temperature], lr=0.01, max_iter=200)\n",
        "\n",
        "        def eval():\n",
        "            optimizer.zero_grad()\n",
        "            loss = nll_criterion(self.temperature_scale(logits), labels)\n",
        "            loss.backward()\n",
        "            return loss\n",
        "\n",
        "        optimizer.step(eval)\n",
        "\n",
        "        # Calculate metrics after temperature scaling\n",
        "        after_temperature_nll = nll_criterion(self.temperature_scale(logits), labels).item()\n",
        "        after_temperature_ece = ece_criterion(self.temperature_scale(logits), labels).item()\n",
        "        print(f'Optimal temperature: {self.temperature.item():.4f}')\n",
        "        print(f'After temperature - NLL: {after_temperature_nll:.4f}, ECE: {after_temperature_ece:.4f}')\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "class ECELoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Calculates the Expected Calibration Error (ECE).\n",
        "    ECE divides predictions into bins and measures the gap between\n",
        "    confidence and accuracy in each bin.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_bins=15):\n",
        "        super(ECELoss, self).__init__()\n",
        "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "        self.bin_lowers = bin_boundaries[:-1]\n",
        "        self.bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        softmaxes = F.softmax(logits, dim=1)\n",
        "        confidences, predictions = torch.max(softmaxes, 1)\n",
        "        accuracies = predictions.eq(labels)\n",
        "\n",
        "        ece = torch.zeros(1, device=logits.device)\n",
        "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
        "            # Calculate |confidence - accuracy| in each bin\n",
        "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
        "            prop_in_bin = in_bin.float().mean()\n",
        "            if prop_in_bin.item() > 0:\n",
        "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "        return ece"
      ],
      "metadata": {
        "id": "zMB2hfCFEfJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_logits_and_labels(model, loader, device):\n",
        "    \"\"\"\n",
        "    Collect all logits and labels from a data loader.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    logits_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm.tqdm(loader, desc=\"Collecting predictions\"):\n",
        "            inputs = inputs.to(device)\n",
        "            logits = model(inputs)\n",
        "            logits_list.append(logits.cpu())\n",
        "            labels_list.append(labels)\n",
        "\n",
        "    logits = torch.cat(logits_list)\n",
        "    labels = torch.cat(labels_list).squeeze()\n",
        "\n",
        "    return logits, labels\n",
        "\n",
        "\n",
        "# Collect predictions on test set\n",
        "test_logits_before, test_labels = collect_logits_and_labels(model, test_loader, device)\n",
        "test_labels=test_labels.long()\n",
        "# Calculate metrics\n",
        "softmaxes = F.softmax(test_logits_before, dim=1)\n",
        "_, predictions = torch.max(softmaxes, 1)\n",
        "accuracy = (predictions == test_labels).float().mean().item()\n",
        "\n",
        "ece_criterion = ECELoss()\n",
        "ece_before = ece_criterion(test_logits_before, test_labels).item()\n",
        "\n",
        "nll_criterion = nn.CrossEntropyLoss()\n",
        "nll_before = nll_criterion(test_logits_before, test_labels).item()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"BEFORE TEMPERATURE SCALING\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"ECE: {ece_before:.4f}\")\n",
        "print(f\"NLL: {nll_before:.4f}\")"
      ],
      "metadata": {
        "id": "om-OvMrSZ1--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap model with temperature scaling\n",
        "scaled_model = ModelWithTemperature(model)\n",
        "\n",
        "# Tune temperature on validation set\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TUNING TEMPERATURE ON VALIDATION SET\")\n",
        "print(\"=\"*50)\n",
        "scaled_model.set_temperature(val_loader)\n",
        "\n",
        "print(f\"\\nOptimal temperature: {scaled_model.temperature.item():.4f}\")"
      ],
      "metadata": {
        "id": "_MaNu9nxZ8xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect predictions after temperature scaling\n",
        "test_logits_after, _ = collect_logits_and_labels(scaled_model, test_loader, device)\n",
        "\n",
        "# Calculate metrics\n",
        "softmaxes_after = F.softmax(test_logits_after, dim=1)\n",
        "_, predictions_after = torch.max(softmaxes_after, 1)\n",
        "accuracy_after = (predictions_after == test_labels).float().mean().item()\n",
        "\n",
        "ece_after = ece_criterion(test_logits_after, test_labels).item()\n",
        "nll_after = nll_criterion(test_logits_after, test_labels).item()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"AFTER TEMPERATURE SCALING\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_after:.4f}\")\n",
        "print(f\"ECE: {ece_after:.4f}\")\n",
        "print(f\"NLL: {nll_after:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"IMPROVEMENT\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy change: {accuracy_after - accuracy:.4f}\")\n",
        "print(f\"ECE reduction: {ece_before - ece_after:.4f} ({(1 - ece_after/ece_before)*100:.1f}% improvement)\")\n",
        "print(f\"NLL reduction: {nll_before - nll_after:.4f}\")"
      ],
      "metadata": {
        "id": "yCtfx2VhaBZ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}